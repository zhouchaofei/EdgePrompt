"""
MDDæ•°æ®é›†å¤„ç† - Baselineå®éªŒç‰ˆæœ¬
ä»REST-meta-MDDæ•°æ®é›†æå–AAL-116 ROIçš„æ—¶é—´åºåˆ—å¹¶è®¡ç®—FCçŸ©é˜µ

åŠŸèƒ½ï¼š
1. åŠ è½½å·²ä¸‹è½½çš„REST-meta-MDDæ•°æ®
2. ä»æ–‡ä»¶åæå–æ ‡ç­¾
3. åªæå–AALå›¾è°±çš„116ä¸ªROIï¼ˆåˆ—1-116ï¼‰
4. è®¡ç®—Pearson FCçŸ©é˜µ
5. ä¿å­˜ä¸ºnpzæ ¼å¼
"""

import os
import numpy as np
import pandas as pd
import scipy.io as sio
from scipy import stats
import glob
import re
import warnings

warnings.filterwarnings('ignore')


class MDDBaselineProcessor:
    """MDDæ•°æ®å¤„ç†å™¨ - Baselineç‰ˆæœ¬"""

    def __init__(self, data_folder='./data'):
        """
        Args:
            data_folder: æ•°æ®ä¿å­˜æ ¹ç›®å½•
        """
        self.data_folder = data_folder
        self.mdd_path = os.path.join(data_folder, 'REST-meta-MDD')
        self.baseline_path = os.path.join(self.mdd_path, 'baseline')

        os.makedirs(self.baseline_path, exist_ok=True)

        print(f"=" * 60)
        print(f"MDD Baseline Processor")
        print(f"=" * 60)
        print(f"Data path: {self.mdd_path}")
        print(f"Save to: {self.baseline_path}")
        print(f"=" * 60)

    def load_roi_signals(self):
        """
        åŠ è½½ROIä¿¡å·æ•°æ®ï¼ˆåªæå–AAL-116ï¼‰

        Returns:
            timeseries_list: æ—¶é—´åºåˆ—åˆ—è¡¨ [N_subjects, (T, 116)]
            labels: æ ‡ç­¾åˆ—è¡¨ (0=HC, 1=MDD)
            subject_ids: è¢«è¯•IDåˆ—è¡¨
        """
        print(f"\n1. Loading ROI signals from REST-meta-MDD...")

        # ROIæ•°æ®è·¯å¾„
        roi_folder = os.path.join(
            self.mdd_path,
            'Results',
            'ROISignals_FunImgARCWF'
        )

        if not os.path.exists(roi_folder):
            raise FileNotFoundError(
                f"ROI folder not found: {roi_folder}\n"
                f"Please ensure REST-meta-MDD data is downloaded and extracted correctly."
            )

        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶
        mat_files = glob.glob(
            os.path.join(roi_folder, '**', '*.mat'),
            recursive=True
        )

        print(f"   Found {len(mat_files)} .mat files")

        if len(mat_files) == 0:
            raise ValueError(f"No .mat files found in {roi_folder}")

        timeseries_list = []
        labels = []
        subject_ids = []

        # ç»Ÿè®¡ä¿¡æ¯
        label_counts = {'MDD': 0, 'HC': 0, 'unknown': 0, 'error': 0}

        for file_idx, file_path in enumerate(mat_files):
            try:
                filename = os.path.basename(file_path)

                # ============================================
                # ä»æ–‡ä»¶åæå–æ ‡ç­¾
                # æ ¼å¼: ROISignals_S1-1-0001.mat
                # -1- = MDDæ‚£è€…, -2- = å¥åº·å¯¹ç…§
                # ============================================
                match = re.search(r'-(\d)-', filename)

                if not match:
                    label_counts['unknown'] += 1
                    continue

                group_code = int(match.group(1))

                if group_code == 1:
                    label = 1  # MDD
                    label_counts['MDD'] += 1
                elif group_code == 2:
                    label = 0  # HC
                    label_counts['HC'] += 1
                else:
                    label_counts['unknown'] += 1
                    continue

                # åŠ è½½.matæ–‡ä»¶
                mat_data = sio.loadmat(file_path)

                # æŸ¥æ‰¾æ—¶é—´åºåˆ—æ•°æ®
                if 'ROISignals' not in mat_data:
                    label_counts['error'] += 1
                    continue

                time_series = mat_data['ROISignals']  # [T, 1833]

                # ============================================
                # å…³é”®ï¼šåªæå–AALå›¾è°±çš„116ä¸ªROIï¼ˆåˆ—1-116ï¼‰
                # ============================================
                if time_series.shape[1] < 116:
                    label_counts['error'] += 1
                    continue

                time_series = time_series[:, :116]  # [T, 116]

                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if time_series.shape[0] < 50:  # æ—¶é—´ç‚¹å¤ªå°‘
                    label_counts['error'] += 1
                    continue

                # æ£€æŸ¥NaNå’ŒInf
                if np.isnan(time_series).any() or np.isinf(time_series).any():
                    # æ¸…ç†å¼‚å¸¸å€¼
                    time_series = np.nan_to_num(
                        time_series,
                        nan=0.0,
                        posinf=0.0,
                        neginf=0.0
                    )

                # æå–è¢«è¯•ID
                subject_id = filename.split('.')[0]

                # ä¿å­˜æ•°æ®
                timeseries_list.append(time_series)
                labels.append(label)
                subject_ids.append(subject_id)

                if (file_idx + 1) % 50 == 0:
                    print(f"   Processed: {file_idx + 1}/{len(mat_files)}")

            except Exception as e:
                label_counts['error'] += 1
                if label_counts['error'] <= 5:
                    print(f"   Warning: Failed to process {filename}: {e}")
                continue

        labels = np.array(labels)

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\n   Loading completed:")
        print(f"   ----------------------------------------")
        print(f"   Successfully loaded: {len(timeseries_list)} subjects")
        print(f"     - MDD patients (label=1): {label_counts['MDD']}")
        print(f"     - Healthy controls (label=0): {label_counts['HC']}")
        print(f"   Failed:")
        print(f"     - Unknown label format: {label_counts['unknown']}")
        print(f"     - Processing errors: {label_counts['error']}")

        # éªŒè¯æ ‡ç­¾å¹³è¡¡æ€§
        if label_counts['MDD'] > 0 and label_counts['HC'] > 0:
            ratio = max(label_counts['MDD'], label_counts['HC']) / \
                    min(label_counts['MDD'], label_counts['HC'])
            print(f"\n   Class balance ratio: {ratio:.2f}:1", end=" ")
            if ratio > 3:
                print("(âš ï¸  Imbalanced)")
            else:
                print("(âœ… Balanced)")

        # æ‰“å°æ—¶é—´åºåˆ—é•¿åº¦ä¿¡æ¯
        ts_lengths = [ts.shape[0] for ts in timeseries_list]
        print(f"\n   Time series lengths:")
        print(f"     Min: {min(ts_lengths)}")
        print(f"     Max: {max(ts_lengths)}")
        print(f"     Mean: {np.mean(ts_lengths):.1f}")
        print(f"     Median: {np.median(ts_lengths):.1f}")

        return timeseries_list, labels, subject_ids

    def compute_fc_matrices(self, timeseries_list, method='pearson'):
        """
        è®¡ç®—åŠŸèƒ½è¿æ¥çŸ©é˜µ

        Args:
            timeseries_list: æ—¶é—´åºåˆ—åˆ—è¡¨
            method: 'pearson' or 'spearman'

        Returns:
            fc_matrices: FCçŸ©é˜µåˆ—è¡¨ [N_subjects, (116, 116)]
        """
        print(f"\n2. Computing FC matrices ({method} correlation)...")

        fc_matrices = []

        for i, ts in enumerate(timeseries_list):
            # è®¡ç®—ç›¸å…³çŸ©é˜µ
            if method == 'pearson':
                fc = np.corrcoef(ts.T)  # [T, 116] -> [116, 116]
            elif method == 'spearman':
                fc = stats.spearmanr(ts)[0]
            else:
                raise ValueError(f"Unknown method: {method}")

            # å¤„ç†NaNå’ŒInf
            fc = np.nan_to_num(fc, nan=0.0, posinf=1.0, neginf=-1.0)

            # å¯¹è§’çº¿è®¾ä¸º0ï¼ˆå»æ‰è‡ªç›¸å…³ï¼‰
            np.fill_diagonal(fc, 0)

            fc_matrices.append(fc)

            if (i + 1) % 100 == 0:
                print(f"   Computed: {i + 1}/{len(timeseries_list)}")

        fc_matrices = np.array(fc_matrices)

        print(f"\n   FC matrices statistics:")
        print(f"     Shape: {fc_matrices.shape}")
        print(f"     Mean: {fc_matrices.mean():.4f}")
        print(f"     Std: {fc_matrices.std():.4f}")
        print(f"     Min: {fc_matrices.min():.4f}")
        print(f"     Max: {fc_matrices.max():.4f}")

        # æ£€æŸ¥å¼‚å¸¸å€¼
        extreme_values = np.sum(np.abs(fc_matrices) > 0.99)
        total_values = fc_matrices.size
        print(f"     Extreme values (>0.99): {extreme_values} "
              f"({extreme_values / total_values * 100:.2f}%)")

        return fc_matrices

    def save_data(self, fc_matrices, labels, subject_ids, method='pearson'):
        """
        ä¿å­˜æ•°æ®ä¸ºnpzæ ¼å¼

        Args:
            fc_matrices: [N_subjects, 116, 116]
            labels: [N_subjects]
            subject_ids: [N_subjects]
            method: FCè®¡ç®—æ–¹æ³•
        """
        print(f"\n3. Saving data...")

        # æ„å»ºæ–‡ä»¶å
        filename = f'mdd_aal116_{method}_fc.npz'
        save_path = os.path.join(self.baseline_path, filename)

        # ä¿å­˜
        np.savez_compressed(
            save_path,
            fc_matrices=fc_matrices,
            labels=labels,
            subject_ids=subject_ids,
            atlas='aal',
            n_rois=116,
            method=method,
            n_subjects=len(labels)
        )

        print(f"   âœ… Saved to: {save_path}")

        # ä¿å­˜å…ƒä¿¡æ¯ä¸ºæ–‡æœ¬
        meta_file = os.path.join(self.baseline_path, 'mdd_aal116_meta.txt')
        with open(meta_file, 'w') as f:
            f.write(f"REST-meta-MDD Dataset - Baseline Format\n")
            f.write(f"=" * 60 + "\n")
            f.write(f"Atlas: AAL-116\n")
            f.write(f"FC Method: {method}\n")
            f.write(f"Number of subjects: {len(labels)}\n")
            f.write(f"Number of ROIs: 116\n")
            f.write(f"FC matrix shape: {fc_matrices.shape}\n")
            f.write(f"\nLabel distribution:\n")
            unique, counts = np.unique(labels, return_counts=True)
            for u, c in zip(unique, counts):
                label_name = 'HC' if u == 0 else 'MDD'
                f.write(f"  {label_name} (label={u}): {c}\n")
            f.write(f"\nFC statistics:\n")
            f.write(f"  Mean: {fc_matrices.mean():.4f}\n")
            f.write(f"  Std: {fc_matrices.std():.4f}\n")
            f.write(f"  Min: {fc_matrices.min():.4f}\n")
            f.write(f"  Max: {fc_matrices.max():.4f}\n")

        print(f"   âœ… Meta info saved to: {meta_file}")

        return save_path

    def process_and_save(self, fc_method='pearson'):
        """
        å®Œæ•´çš„å¤„ç†æµç¨‹

        Args:
            fc_method: FCè®¡ç®—æ–¹æ³•

        Returns:
            save_path: ä¿å­˜è·¯å¾„
        """
        # åŠ è½½æ—¶é—´åºåˆ—
        timeseries_list, labels, subject_ids = self.load_roi_signals()

        if len(timeseries_list) == 0:
            print("\nâŒ No valid subjects found!")
            return None

        # è®¡ç®—FCçŸ©é˜µ
        fc_matrices = self.compute_fc_matrices(timeseries_list, fc_method)

        # ä¿å­˜
        save_path = self.save_data(fc_matrices, labels, subject_ids, fc_method)

        print(f"\n{'=' * 60}")
        print(f"âœ… Processing completed successfully!")
        print(f"{'=' * 60}")

        return save_path


def load_mdd_baseline(data_folder='./data', method='pearson'):
    """
    åŠ è½½å¤„ç†å¥½çš„MDD baselineæ•°æ®

    Args:
        data_folder: æ•°æ®æ ¹ç›®å½•
        method: FCæ–¹æ³•

    Returns:
        fc_matrices: [N, 116, 116]
        labels: [N]
        subject_ids: [N]
        meta: å…ƒä¿¡æ¯å­—å…¸
    """
    baseline_path = os.path.join(data_folder, 'REST-meta-MDD', 'baseline')
    filename = f'mdd_aal116_{method}_fc.npz'
    file_path = os.path.join(baseline_path, filename)

    if not os.path.exists(file_path):
        raise FileNotFoundError(
            f"Data file not found: {file_path}\n"
            f"Please run: python prepare_mdd_baseline.py"
        )

    data = np.load(file_path, allow_pickle=True)

    fc_matrices = data['fc_matrices']
    labels = data['labels']
    subject_ids = data['subject_ids']

    meta = {
        'atlas': str(data['atlas']),
        'n_rois': int(data['n_rois']),
        'method': str(data['method']),
        'n_subjects': int(data['n_subjects'])
    }

    print(f"Loaded MDD baseline data:")
    print(f"  Shape: {fc_matrices.shape}")
    print(f"  Atlas: {meta['atlas']}")
    print(f"  ROIs: {meta['n_rois']}")
    print(f"  Method: {meta['method']}")

    return fc_matrices, labels, subject_ids, meta


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description='Prepare REST-meta-MDD data for baseline experiment'
    )
    parser.add_argument(
        '--data_folder',
        type=str,
        default='./data',
        help='Root folder for data'
    )
    parser.add_argument(
        '--fc_method',
        type=str,
        default='pearson',
        choices=['pearson', 'spearman'],
        help='FC computation method'
    )

    args = parser.parse_args()

    # åˆ›å»ºå¤„ç†å™¨
    processor = MDDBaselineProcessor(data_folder=args.data_folder)

    # å¤„ç†å¹¶ä¿å­˜
    save_path = processor.process_and_save(fc_method=args.fc_method)

    if save_path:
        print(f"\nğŸ“Š To use this data:")
        print(f"   from prepare_mdd_baseline import load_mdd_baseline")
        print(f"   fc, labels, ids, meta = load_mdd_baseline()")