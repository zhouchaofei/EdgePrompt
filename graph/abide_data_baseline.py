"""
ABIDEæ•°æ®é›†å¤„ç† - Baselineå®éªŒç‰ˆæœ¬
ç›´æ¥ç”ŸæˆFCçŸ©é˜µï¼Œç”¨äºä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»

åŠŸèƒ½ï¼š
1. ä¸‹è½½ABIDEæ•°æ®ï¼ˆä½¿ç”¨nilearnï¼‰
2. æå–æ—¶é—´åºåˆ—ï¼ˆä¸ç»Ÿä¸€é•¿åº¦ï¼‰
3. è®¡ç®—Pearson FCçŸ©é˜µ
4. ä¿å­˜ä¸ºnpzæ ¼å¼
"""

import os
import numpy as np
import pandas as pd
from nilearn.datasets import fetch_abide_pcp
from scipy import stats
import warnings

warnings.filterwarnings('ignore')


class ABIDEBaselineProcessor:
    """ABIDEæ•°æ®å¤„ç†å™¨ - Baselineç‰ˆæœ¬"""

    def __init__(self, data_folder='./data', pipeline='cpac', atlas='aal'):
        """
        Args:
            data_folder: æ•°æ®ä¿å­˜æ ¹ç›®å½•
            pipeline: é¢„å¤„ç†ç®¡é“ (cpac/ccs/niak/dparsf)
            atlas: è„‘å›¾è°± (aal/ho/cc200/cc400)
        """
        self.data_folder = data_folder
        self.pipeline = pipeline
        self.atlas = atlas

        self.abide_path = os.path.join(data_folder, 'ABIDE')
        self.baseline_path = os.path.join(self.abide_path, 'baseline')

        os.makedirs(self.baseline_path, exist_ok=True)

        print(f"=" * 60)
        print(f"ABIDE Baseline Processor")
        print(f"=" * 60)
        print(f"Pipeline: {pipeline}")
        print(f"Atlas: {atlas}")
        print(f"Save to: {self.baseline_path}")
        print(f"=" * 60)

    def download_and_extract(self, n_subjects=None):
        """
        ä¸‹è½½ABIDEæ•°æ®å¹¶æå–æ—¶é—´åºåˆ—

        Args:
            n_subjects: ä¸‹è½½çš„è¢«è¯•æ•°é‡ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰

        Returns:
            timeseries_list: æ—¶é—´åºåˆ—åˆ—è¡¨
            labels: æ ‡ç­¾åˆ—è¡¨ (0=HC, 1=ASD)
            subject_ids: è¢«è¯•IDåˆ—è¡¨
        """
        print(f"\n1. Downloading ABIDE data...")
        print(f"   This may take a while on first run...")

        # ç¡®å®šderivativeså‚æ•°
        if self.atlas == 'aal':
            derivatives = 'rois_aal'
            print(f"   Using AAL-116 atlas")
        elif self.atlas == 'ho':
            derivatives = 'rois_ho'
            print(f"   Using Harvard-Oxford atlas")
        elif self.atlas == 'cc200':
            derivatives = 'rois_cc200'
            print(f"   Using CC200 atlas")
        elif self.atlas == 'cc400':
            derivatives = 'rois_cc400'
            print(f"   Using CC400 atlas")
        else:
            derivatives = 'rois_aal'
            print(f"   Unknown atlas, using AAL-116")

        # ä¸‹è½½æ•°æ®
        data = fetch_abide_pcp(
            data_dir=self.abide_path,
            pipeline=self.pipeline,
            band_pass_filtering=True,
            global_signal_regression=False,
            derivatives=[derivatives],
            n_subjects=n_subjects,
            quality_checked=True,  # åªä¸‹è½½è´¨æ£€é€šè¿‡çš„æ•°æ®
            verbose=1
        )

        print(f"\n   Downloaded {len(data.phenotypic)} subjects")

        # æå–ROIæ—¶é—´åºåˆ—
        print(f"\n2. Extracting time series...")

        timeseries_list = []
        labels = []
        subject_ids = []

        # è·å–ROIæ•°æ®
        rois_data = getattr(data, derivatives, None)

        if rois_data is None:
            raise ValueError(f"No ROI data found for atlas: {self.atlas}")

        # è·å–æ ‡ç­¾ (DX_GROUP: 1=ASD, 2=Control)
        phenotypic = data.phenotypic
        dx_labels = phenotypic['DX_GROUP'].values

        valid_count = 0
        invalid_count = 0

        for idx, roi_file in enumerate(rois_data):
            try:
                # åŠ è½½æ—¶é—´åºåˆ—
                if isinstance(roi_file, str) and os.path.exists(roi_file):
                    ts = pd.read_csv(roi_file, sep='\t', header=0).values
                elif isinstance(roi_file, np.ndarray):
                    ts = roi_file
                else:
                    invalid_count += 1
                    continue

                # åŸºæœ¬è´¨é‡æ£€æŸ¥
                if ts.shape[0] < 50:  # æ—¶é—´ç‚¹å¤ªå°‘
                    invalid_count += 1
                    continue

                if np.isnan(ts).any() or np.isinf(ts).any():
                    # å°è¯•æ¸…ç†
                    ts = np.nan_to_num(ts, nan=0.0, posinf=0.0, neginf=0.0)

                # æå–æ ‡ç­¾å’ŒID
                label = dx_labels[idx] - 1  # è½¬ä¸º0/1 (0=HC, 1=ASD)
                subject_id = phenotypic.iloc[idx]['SUB_ID']

                # ä¿å­˜
                timeseries_list.append(ts)
                labels.append(label)
                subject_ids.append(subject_id)

                valid_count += 1

                if valid_count % 50 == 0:
                    print(f"   Processed: {valid_count}/{len(rois_data)}")

            except Exception as e:
                invalid_count += 1
                if invalid_count <= 5:
                    print(f"   Warning: Failed to process subject {idx}: {e}")
                continue

        labels = np.array(labels)

        print(f"\n   Successfully loaded: {valid_count} subjects")
        print(f"   Failed: {invalid_count} subjects")

        # æ‰“å°æ ‡ç­¾åˆ†å¸ƒ
        unique, counts = np.unique(labels, return_counts=True)
        print(f"\n   Label distribution:")
        for u, c in zip(unique, counts):
            label_name = 'HC' if u == 0 else 'ASD'
            print(f"     {label_name} (label={u}): {c} subjects")

        return timeseries_list, labels, subject_ids

    def compute_fc_matrices(self, timeseries_list, method='pearson'):
        """
        è®¡ç®—åŠŸèƒ½è¿æ¥çŸ©é˜µ

        Args:
            timeseries_list: æ—¶é—´åºåˆ—åˆ—è¡¨
            method: 'pearson' or 'spearman'

        Returns:
            fc_matrices: FCçŸ©é˜µåˆ—è¡¨ [N_subjects, (N_ROI, N_ROI)]
        """
        print(f"\n3. Computing FC matrices ({method} correlation)...")

        fc_matrices = []

        for i, ts in enumerate(timeseries_list):
            # è®¡ç®—ç›¸å…³çŸ©é˜µ
            if method == 'pearson':
                fc = np.corrcoef(ts.T)  # [T, N_ROI] -> [N_ROI, N_ROI]
            elif method == 'spearman':
                fc = stats.spearmanr(ts)[0]
            else:
                raise ValueError(f"Unknown method: {method}")

            # å¤„ç†NaNå’ŒInf
            fc = np.nan_to_num(fc, nan=0.0, posinf=1.0, neginf=-1.0)

            # å¯¹è§’çº¿è®¾ä¸º0ï¼ˆå»æ‰è‡ªç›¸å…³ï¼‰
            np.fill_diagonal(fc, 0)

            fc_matrices.append(fc)

            if (i + 1) % 100 == 0:
                print(f"   Computed: {i + 1}/{len(timeseries_list)}")

        fc_matrices = np.array(fc_matrices)

        print(f"   FC matrices shape: {fc_matrices.shape}")
        print(f"   FC statistics:")
        print(f"     Mean: {fc_matrices.mean():.4f}")
        print(f"     Std: {fc_matrices.std():.4f}")
        print(f"     Min: {fc_matrices.min():.4f}")
        print(f"     Max: {fc_matrices.max():.4f}")

        return fc_matrices

    def save_data(self, fc_matrices, labels, subject_ids, method='pearson'):
        """
        ä¿å­˜æ•°æ®ä¸ºnpzæ ¼å¼

        Args:
            fc_matrices: [N_subjects, N_ROI, N_ROI]
            labels: [N_subjects]
            subject_ids: [N_subjects]
            method: FCè®¡ç®—æ–¹æ³•
        """
        print(f"\n4. Saving data...")

        # æ„å»ºæ–‡ä»¶å
        filename = f'abide_{self.atlas}_{method}_fc.npz'
        save_path = os.path.join(self.baseline_path, filename)

        # ä¿å­˜
        np.savez_compressed(
            save_path,
            fc_matrices=fc_matrices,
            labels=labels,
            subject_ids=subject_ids,
            atlas=self.atlas,
            method=method,
            n_subjects=len(labels),
            n_rois=fc_matrices.shape[1]
        )

        print(f"   Saved to: {save_path}")

        # ä¿å­˜å…ƒä¿¡æ¯ä¸ºæ–‡æœ¬
        meta_file = os.path.join(self.baseline_path, f'abide_{self.atlas}_meta.txt')
        with open(meta_file, 'w') as f:
            f.write(f"ABIDE Dataset - Baseline Format\n")
            f.write(f"=" * 60 + "\n")
            f.write(f"Atlas: {self.atlas}\n")
            f.write(f"Pipeline: {self.pipeline}\n")
            f.write(f"FC Method: {method}\n")
            f.write(f"Number of subjects: {len(labels)}\n")
            f.write(f"Number of ROIs: {fc_matrices.shape[1]}\n")
            f.write(f"FC matrix shape: {fc_matrices.shape}\n")
            f.write(f"\nLabel distribution:\n")
            unique, counts = np.unique(labels, return_counts=True)
            for u, c in zip(unique, counts):
                label_name = 'HC' if u == 0 else 'ASD'
                f.write(f"  {label_name} (label={u}): {c}\n")

        print(f"   Meta info saved to: {meta_file}")

        return save_path

    def process_and_save(self, n_subjects=None, fc_method='pearson'):
        """
        å®Œæ•´çš„å¤„ç†æµç¨‹

        Args:
            n_subjects: è¢«è¯•æ•°é‡
            fc_method: FCè®¡ç®—æ–¹æ³•

        Returns:
            save_path: ä¿å­˜è·¯å¾„
        """
        # ä¸‹è½½å’Œæå–æ—¶é—´åºåˆ—
        timeseries_list, labels, subject_ids = self.download_and_extract(n_subjects)

        if len(timeseries_list) == 0:
            print("\nâŒ No valid subjects found!")
            return None

        # è®¡ç®—FCçŸ©é˜µ
        fc_matrices = self.compute_fc_matrices(timeseries_list, fc_method)

        # ä¿å­˜
        save_path = self.save_data(fc_matrices, labels, subject_ids, fc_method)

        print(f"\n{'=' * 60}")
        print(f"âœ… Processing completed successfully!")
        print(f"{'=' * 60}")

        return save_path


def load_abide_baseline(data_folder='./data', atlas='aal', method='pearson'):
    """
    åŠ è½½å¤„ç†å¥½çš„ABIDE baselineæ•°æ®

    Args:
        data_folder: æ•°æ®æ ¹ç›®å½•
        atlas: è„‘å›¾è°±
        method: FCæ–¹æ³•

    Returns:
        fc_matrices: [N, N_ROI, N_ROI]
        labels: [N]
        subject_ids: [N]
        meta: å…ƒä¿¡æ¯å­—å…¸
    """
    baseline_path = os.path.join(data_folder, 'ABIDE', 'baseline')
    filename = f'abide_{atlas}_{method}_fc.npz'
    file_path = os.path.join(baseline_path, filename)

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Data file not found: {file_path}\n"
                                f"Please run: python prepare_abide_baseline.py")

    data = np.load(file_path, allow_pickle=True)

    fc_matrices = data['fc_matrices']
    labels = data['labels']
    subject_ids = data['subject_ids']

    meta = {
        'atlas': str(data['atlas']),
        'method': str(data['method']),
        'n_subjects': int(data['n_subjects']),
        'n_rois': int(data['n_rois'])
    }

    print(f"Loaded ABIDE baseline data:")
    print(f"  Shape: {fc_matrices.shape}")
    print(f"  Atlas: {meta['atlas']}")
    print(f"  Method: {meta['method']}")

    return fc_matrices, labels, subject_ids, meta


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Prepare ABIDE data for baseline experiment')
    parser.add_argument('--data_folder', type=str, default='./data',
                        help='Root folder for data')
    parser.add_argument('--pipeline', type=str, default='cpac',
                        choices=['cpac', 'ccs', 'niak', 'dparsf'],
                        help='Preprocessing pipeline')
    parser.add_argument('--atlas', type=str, default='aal',
                        choices=['aal', 'ho', 'cc200', 'cc400'],
                        help='Brain atlas')
    parser.add_argument('--n_subjects', type=int, default=None,
                        help='Number of subjects to download (None=all)')
    parser.add_argument('--fc_method', type=str, default='pearson',
                        choices=['pearson', 'spearman'],
                        help='FC computation method')

    args = parser.parse_args()

    # åˆ›å»ºå¤„ç†å™¨
    processor = ABIDEBaselineProcessor(
        data_folder=args.data_folder,
        pipeline=args.pipeline,
        atlas=args.atlas
    )

    # å¤„ç†å¹¶ä¿å­˜
    save_path = processor.process_and_save(
        n_subjects=args.n_subjects,
        fc_method=args.fc_method
    )

    if save_path:
        print(f"\nğŸ“Š To use this data:")
        print(f"   from prepare_abide_baseline import load_abide_baseline")
        print(f"   fc, labels, ids, meta = load_abide_baseline()")