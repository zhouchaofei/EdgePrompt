"""
ç¦»çº¿èŠ‚ç‚¹é¢„è®­ç»ƒ - å¢å¼ºç‰ˆ
ä¿®æ”¹ï¼š
1. è¾“å…¥å±‚æ·»åŠ BatchNorm
2. å¢åŠ mask_ratioåˆ°0.6
3. ä¼˜åŒ–è®­ç»ƒç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.utils.data import Dataset, DataLoader
import os
from datetime import datetime


class TimeSeriesWindowDataset(Dataset):
    """æ»‘çª—æ—¶é—´åºåˆ—æ•°æ®é›†"""

    def __init__(self, timeseries_list, window_size=64, stride=32):
        self.window_size = window_size
        self.stride = stride
        self.chunks = []

        print(f"\nå‡†å¤‡é¢„è®­ç»ƒæ•°æ®...")
        print(f"  çª—å£å¤§å°: {window_size}")
        print(f"  æ»‘åŠ¨æ­¥é•¿: {stride}")

        for ts_idx, ts in enumerate(timeseries_list):
            T, N_rois = ts.shape

            if T < window_size:
                continue

            num_windows = (T - window_size) // stride + 1

            for roi_idx in range(N_rois):
                roi_signal = ts[:, roi_idx]

                for w in range(num_windows):
                    start = w * stride
                    end = start + window_size
                    chunk = roi_signal[start:end]

                    # Z-score within window
                    mean = np.mean(chunk)
                    std = np.std(chunk) + 1e-6
                    chunk_norm = (chunk - mean) / std

                    if np.any(np.isnan(chunk_norm)) or np.any(np.isinf(chunk_norm)):
                        continue

                    self.chunks.append(chunk_norm)

            if (ts_idx + 1) % 50 == 0:
                print(f"  å¤„ç†è¿›åº¦: {ts_idx + 1}/{len(timeseries_list)}")

        self.chunks = np.array(self.chunks, dtype=np.float32)

        print(f"\nâœ“ æ•°æ®å‡†å¤‡å®Œæˆ")
        print(f"  æ€»æ ·æœ¬æ•°: {len(self.chunks)}")
        print(f"  æ ·æœ¬å½¢çŠ¶: {self.chunks.shape}")
        print(f"  æ•°æ®ç»Ÿè®¡: mean={self.chunks.mean():.4f}, std={self.chunks.std():.4f}")

    def __len__(self):
        return len(self.chunks)

    def __getitem__(self, idx):
        return torch.FloatTensor(self.chunks[idx])


class MAE_Encoder(nn.Module):
    """1D-CNN Encoder with Input Batch Normalization"""

    def __init__(self, input_length, embedding_dim=64, dropout=0.1):
        super().__init__()

        self.embedding_dim = embedding_dim

        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šè¾“å…¥å±‚BatchNorm
        self.input_bn = nn.BatchNorm1d(1)

        # 3å±‚1D-CNN
        self.conv1 = nn.Conv1d(1, 32, kernel_size=7, padding=3)
        self.bn1 = nn.BatchNorm1d(32)
        self.pool1 = nn.MaxPool1d(2)

        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)
        self.bn2 = nn.BatchNorm1d(64)
        self.pool2 = nn.MaxPool1d(2)

        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm1d(128)

        self.global_pool = nn.AdaptiveAvgPool1d(1)

        self.fc = nn.Sequential(
            nn.Linear(128, embedding_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        if x.dim() == 2:
            x = x.unsqueeze(1)  # [B, 1, L]

        # ğŸ”¥ è¾“å…¥å½’ä¸€åŒ–
        x = self.input_bn(x)

        # Encoder
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.pool1(x)
        x = self.dropout(x)

        x = self.relu(self.bn2(self.conv2(x)))
        x = self.pool2(x)
        x = self.dropout(x)

        x = self.relu(self.bn3(self.conv3(x)))

        # Global pooling
        x = self.global_pool(x)
        x = x.squeeze(-1)

        # Embedding
        embedding = self.fc(x)

        return embedding


class MAE_Decoder(nn.Module):
    """1D-CNN Transpose Decoder"""

    def __init__(self, embedding_dim, output_length, dropout=0.1):
        super().__init__()

        self.output_length = output_length

        self.fc = nn.Sequential(
            nn.Linear(embedding_dim, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 128 * (output_length // 4))
        )

        self.deconv1 = nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1)
        self.bn1 = nn.BatchNorm1d(64)

        self.deconv2 = nn.ConvTranspose1d(64, 32, kernel_size=4, stride=2, padding=1)
        self.bn2 = nn.BatchNorm1d(32)

        self.deconv3 = nn.Conv1d(32, 1, kernel_size=3, padding=1)

        self.relu = nn.ReLU()

    def forward(self, embedding):
        x = self.fc(embedding)
        x = x.view(x.size(0), 128, -1)

        x = self.relu(self.bn1(self.deconv1(x)))
        x = self.relu(self.bn2(self.deconv2(x)))
        x = self.deconv3(x)

        if x.size(2) != self.output_length:
            x = F.interpolate(x, size=self.output_length, mode='linear', align_corners=False)

        return x.squeeze(1)


class MaskedAutoencoder(nn.Module):
    """Masked Autoencoder"""

    def __init__(self, input_length, embedding_dim=64, mask_ratio=0.6):  # ğŸ”¥ mask_ratioæ”¹ä¸º0.6
        super().__init__()

        self.input_length = input_length
        self.mask_ratio = mask_ratio

        self.encoder = MAE_Encoder(input_length, embedding_dim)
        self.decoder = MAE_Decoder(embedding_dim, input_length)

    def create_mask(self, x):
        B, L = x.shape
        mask = torch.rand(B, L, device=x.device) < self.mask_ratio
        x_masked = x.clone()
        x_masked[mask] = 0
        return x_masked, mask

    def forward(self, x):
        x_masked, mask = self.create_mask(x)
        embedding = self.encoder(x_masked)
        reconstructed = self.decoder(embedding)
        return reconstructed, mask


def train_mae_offline(timeseries_list,
                      window_size=64,
                      embedding_dim=64,
                      mask_ratio=0.6,  # ğŸ”¥ é»˜è®¤0.6
                      epochs=50,
                      batch_size=128,
                      lr=1e-3,
                      device='cuda',
                      save_dir='./pretrained_models'):
    """ç¦»çº¿MAEé¢„è®­ç»ƒï¼ˆå¢å¼ºç‰ˆï¼‰"""

    print("\n" + "="*80)
    print("ç¦»çº¿èŠ‚ç‚¹é¢„è®­ç»ƒ - Masked Autoencoder (Enhanced)")
    print("="*80)
    print(f"çª—å£å¤§å°: {window_size}")
    print(f"Embeddingç»´åº¦: {embedding_dim}")
    print(f"Maskæ¯”ä¾‹: {mask_ratio} (å¢å¼ºç‰ˆ)")  # ğŸ”¥
    print(f"Input BatchNorm: âœ“ Enabled")  # ğŸ”¥
    print(f"Batchå¤§å°: {batch_size}")
    print(f"å­¦ä¹ ç‡: {lr}")
    print(f"è®­ç»ƒè½®æ•°: {epochs}")
    print(f"è®¾å¤‡: {device}")
    print("="*80)

    # å‡†å¤‡æ•°æ®
    dataset = TimeSeriesWindowDataset(
        timeseries_list,
        window_size=window_size,
        stride=window_size // 2
    )

    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )

    # åˆ›å»ºæ¨¡å‹
    model = MaskedAutoencoder(
        input_length=window_size,
        embedding_dim=embedding_dim,
        mask_ratio=mask_ratio
    ).to(device)

    print(f"\næ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=lr,
        weight_decay=1e-4,
        betas=(0.9, 0.95)
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=epochs,
        eta_min=lr * 0.01
    )

    # è®­ç»ƒ
    best_loss = float('inf')
    model.train()

    for epoch in range(epochs):
        epoch_loss = 0
        num_batches = 0

        for batch_x in dataloader:
            batch_x = batch_x.to(device)

            optimizer.zero_grad()

            # Forward
            reconstructed, mask = model(batch_x)

            # åªè®¡ç®—è¢«maskä½ç½®çš„é‡å»ºæŸå¤±
            loss = F.mse_loss(reconstructed[mask], batch_x[mask])

            # Backward
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()

            epoch_loss += loss.item()
            num_batches += 1

        avg_loss = epoch_loss / num_batches
        scheduler.step()

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss

            os.makedirs(save_dir, exist_ok=True)
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': best_loss,
                'config': {
                    'input_length': window_size,
                    'embedding_dim': embedding_dim,
                    'mask_ratio': mask_ratio
                }
            }

            save_path = os.path.join(save_dir, 'node_encoder_best.pth')
            torch.save(checkpoint, save_path)

        if (epoch + 1) % 2 == 0:
            print(f"Epoch {epoch+1}/{epochs}: Loss={avg_loss:.6f} "
                  f"(Best={best_loss:.6f}) LR={optimizer.param_groups[0]['lr']:.6f}")

    print(f"\nâœ“ é¢„è®­ç»ƒå®Œæˆï¼")
    print(f"  æœ€ä½³æŸå¤±: {best_loss:.6f}")
    print(f"  æ¨¡å‹ä¿å­˜è‡³: {save_path}")

    visualize_reconstruction(model, dataset, device, save_dir)

    return model, best_loss


def visualize_reconstruction(model, dataset, device, save_dir):
    """å¯è§†åŒ–é‡å»ºæ•ˆæœ"""
    import matplotlib.pyplot as plt

    print("\nç”Ÿæˆé‡å»ºå¯è§†åŒ–...")

    model.eval()

    indices = np.random.choice(len(dataset), 5, replace=False)

    fig, axes = plt.subplots(5, 1, figsize=(12, 10))

    with torch.no_grad():
        for i, idx in enumerate(indices):
            x = dataset[idx].unsqueeze(0).to(device)

            reconstructed, mask = model(x)

            x = x.cpu().numpy()[0]
            reconstructed = reconstructed.cpu().numpy()[0]
            mask = mask.cpu().numpy()[0]

            axes[i].plot(x, 'b-', label='Original', linewidth=1.5)
            axes[i].plot(reconstructed, 'r--', label='Reconstructed', linewidth=1.5, alpha=0.8)

            mask_indices = np.where(mask)[0]
            axes[i].scatter(mask_indices, x[mask_indices], c='orange', s=10,
                           label='Masked points', zorder=5)

            axes[i].set_title(f'Sample {i+1}')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)

    plt.tight_layout()
    save_path = os.path.join(save_dir, 'reconstruction_visualization.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()

    print(f"  âœ“ å¯è§†åŒ–ä¿å­˜è‡³: {save_path}")


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ç¦»çº¿èŠ‚ç‚¹é¢„è®­ç»ƒï¼ˆå¢å¼ºç‰ˆï¼‰')
    parser.add_argument('--dataset', type=str, required=True,
                        choices=['ABIDE', 'MDD', 'BOTH'])
    parser.add_argument('--data_folder', type=str, default='./data')
    parser.add_argument('--window_size', type=int, default=64)
    parser.add_argument('--embedding_dim', type=int, default=64)
    parser.add_argument('--mask_ratio', type=float, default=0.6)  # ğŸ”¥ é»˜è®¤0.6
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch_size', type=int, default=128)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--device', type=str, default='cuda')
    parser.add_argument('--save_dir', type=str, default='./pretrained_models')

    args = parser.parse_args()

    # åŠ è½½æ•°æ®
    timeseries_list = []

    if args.dataset in ['ABIDE', 'BOTH']:
        from abide_data_baseline import ABIDEBaselineProcessor
        processor = ABIDEBaselineProcessor(data_folder=args.data_folder)
        ts_abide, _, _, _ = processor.download_and_extract(n_subjects=None, apply_zscore=True)
        timeseries_list.extend(ts_abide)
        print(f"åŠ è½½ ABIDE: {len(ts_abide)} ä¸ªè¢«è¯•")

    if args.dataset in ['MDD', 'BOTH']:
        from mdd_data_baseline import MDDBaselineProcessor
        processor = MDDBaselineProcessor(data_folder=args.data_folder)
        ts_mdd, _, _, _ = processor.load_roi_signals(apply_zscore=True)
        timeseries_list.extend(ts_mdd)
        print(f"åŠ è½½ MDD: {len(ts_mdd)} ä¸ªè¢«è¯•")

    print(f"\næ€»å…± {len(timeseries_list)} ä¸ªè¢«è¯•ç”¨äºé¢„è®­ç»ƒ")

    # å¼€å§‹è®­ç»ƒ
    train_mae_offline(
        timeseries_list=timeseries_list,
        window_size=args.window_size,
        embedding_dim=args.embedding_dim,
        mask_ratio=args.mask_ratio,
        epochs=args.epochs,
        batch_size=args.batch_size,
        lr=args.lr,
        device=args.device,
        save_dir=args.save_dir
    )