"""
æ··åˆç‰¹å¾æå–å™¨ - ç»ˆæå¢å¼ºç‰ˆ
ç­–ç•¥ï¼š
1. é¢„è®­ç»ƒç‰¹å¾é‡‡ç”¨ Mean+Std+Max æ± åŒ–ï¼Œä¿ç•™åŠ¨æ€ä¿¡æ¯
2. å¼ºåˆ¶æ‹¼æ¥ç»Ÿè®¡ç‰¹å¾ (FC Profile)ï¼Œä¿è¯ä¸‹é™
"""

import torch
import numpy as np
from node_pretrain import MAE_Encoder
import warnings


def extract_statistical_features_single(timeseries):
    """
    æå–å•ä¸ªè¢«è¯•çš„ç»Ÿè®¡ç‰¹å¾ï¼ˆFC Profileï¼‰

    Args:
        timeseries: (T, N_ROI) æ—¶é—´åºåˆ—

    Returns:
        fc: (N_ROI, N_ROI) åŠŸèƒ½è¿æ¥çŸ©é˜µï¼Œæ¯è¡Œæ˜¯è¯¥ROIä¸å…¶ä»–ROIçš„ç›¸å…³æ€§
    """
    # FC Profile (è¿æ¥æŒ‡çº¹) - éå¸¸å¼ºçš„ç‰¹å¾
    fc = np.corrcoef(timeseries.T)  # (N_ROI, N_ROI)
    np.fill_diagonal(fc, 0)

    return fc


def sliding_window_inference(timeseries, encoder, window_size, stride, device):
    """
    æ»‘çª—æ¨ç† + å¤šé‡æ± åŒ– (Mean/Std/Max)

    Args:
        timeseries: (T,) å•ä¸ªROIçš„æ—¶é—´åºåˆ—
        encoder: é¢„è®­ç»ƒçš„encoder
        window_size: çª—å£å¤§å°
        stride: æ»‘åŠ¨æ­¥é•¿
        device: è®¾å¤‡

    Returns:
        combined_embedding: (embedding_dim * 3,) åŒ…å«Mean/Std/Maxçš„ç»¼åˆç‰¹å¾
    """
    T = len(timeseries)

    if T < window_size:
        padded = np.zeros(window_size)
        padded[:T] = timeseries
        timeseries = padded
        T = window_size

    num_windows = (T - window_size) // stride + 1
    embeddings = []

    for i in range(num_windows):
        start = i * stride
        end = start + window_size
        chunk = timeseries[start:end]

        # Z-score within window
        mean = np.mean(chunk)
        std = np.std(chunk) + 1e-6
        chunk_norm = (chunk - mean) / std

        chunk_tensor = torch.FloatTensor(chunk_norm).unsqueeze(0).to(device)  # [1, L]

        with torch.no_grad():
            embedding = encoder(chunk_tensor)  # [1, D]

        embeddings.append(embedding.cpu().numpy())

    # [Windows, D]
    embeddings = np.vstack(embeddings)

    # ğŸ”¥ å¤šé‡æ± åŒ–ï¼Œä¿ç•™åŠ¨æ€ä¿¡æ¯
    emb_mean = np.mean(embeddings, axis=0)  # [D]
    emb_std = np.std(embeddings, axis=0)    # [D]
    emb_max = np.max(embeddings, axis=0)    # [D]

    # æ‹¼æ¥: [D*3]
    return np.concatenate([emb_mean, emb_std, emb_max])


def extract_node_features_pretrained(timeseries_list, encoder_path,
                                     embedding_dim=64, device='cuda'):
    """
    æå–æ··åˆç‰¹å¾ (Hybrid Features = Deep Features + Statistical Features)

    Args:
        timeseries_list: æ—¶é—´åºåˆ—åˆ—è¡¨ [N_subjects, (T, N_ROI)]
        encoder_path: é¢„è®­ç»ƒencoderè·¯å¾„
        embedding_dim: embeddingç»´åº¦
        device: è®¡ç®—è®¾å¤‡

    Returns:
        features_list: æ··åˆç‰¹å¾åˆ—è¡¨ [N_subjects, (N_ROI, feature_dim)]
                      feature_dim = embedding_dim*3 + N_ROI (å¦‚æœæœ‰é¢„è®­ç»ƒæ¨¡å‹)
                      æˆ– feature_dim = N_ROI (ä»…ç»Ÿè®¡ç‰¹å¾)
    """
    print(f"\n{'='*80}")
    print("æå–æ··åˆèŠ‚ç‚¹ç‰¹å¾ (Temporal + Statistical)")
    print(f"{'='*80}")

    # 1. å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    has_encoder = False
    encoder = None
    window_size = None
    stride = None

    try:
        checkpoint = torch.load(encoder_path, map_location=device)
        config = checkpoint['config']
        window_size = config['input_length']
        stride = window_size // 2

        encoder = MAE_Encoder(input_length=window_size, embedding_dim=embedding_dim).to(device)

        # åŠ è½½æƒé‡
        encoder_state_dict = {}
        for k, v in checkpoint['model_state_dict'].items():
            if k.startswith('encoder.'):
                encoder_state_dict[k.replace('encoder.', '')] = v
        encoder.load_state_dict(encoder_state_dict)
        encoder.eval()  # æ¨ç†æ¨¡å¼

        has_encoder = True
        print("  âœ“ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸï¼Œå°†æå– Deep Features + Statistical Features")
        print(f"    çª—å£å¤§å°: {window_size}")
        print(f"    Embeddingç»´åº¦: {embedding_dim}")
        print(f"    æ»‘åŠ¨æ­¥é•¿: {stride}")
    except Exception as e:
        print(f"  âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("  âš ï¸ å°†åªä½¿ç”¨ç»Ÿè®¡ç‰¹å¾ (Statistical Features Only)")

    features_list = []

    for i, ts in enumerate(timeseries_list):
        # ç¡®ä¿å½¢çŠ¶æ­£ç¡®: (T, N_ROI)
        if ts.shape[0] == 116 and ts.shape[1] != 116:
            ts = ts.T

        T, n_roi = ts.shape

        # A. æå–ç»Ÿè®¡ç‰¹å¾ (Base Feature)
        # shape: (N_ROI, N_ROI) - æ¯ä¸€è¡Œæ˜¯è¯¥ROIä¸å…¶ä»–ROIçš„ç›¸å…³æ€§
        stat_feat = extract_statistical_features_single(ts)

        # B. æå–æ—¶åºç‰¹å¾ (Deep Feature)
        if has_encoder:
            deep_feats = []
            for roi_idx in range(n_roi):
                # å¤šé‡æ± åŒ–: [embedding_dim * 3]
                emb = sliding_window_inference(
                    ts[:, roi_idx], encoder, window_size, stride, device
                )
                deep_feats.append(emb)
            deep_feats = np.array(deep_feats)  # (N_ROI, embedding_dim*3)

            # ğŸ”¥ C. ç‰¹å¾èåˆ
            # æœ€ç»ˆç‰¹å¾ = [Deep(embedding_dim*3) + Stat(N_ROI)] = (embedding_dim*3 + N_ROI)ç»´
            # ä¾‹å¦‚: embedding_dim=64 -> Deep=192, Stat=116 -> Total=308ç»´
            combined = np.column_stack([deep_feats, stat_feat])
        else:
            # ä»…ç»Ÿè®¡ç‰¹å¾
            combined = stat_feat

        features_list.append(combined)

        if (i + 1) % 50 == 0:
            print(f"  å¤„ç†è¿›åº¦: {i + 1}/{len(timeseries_list)}")

    features_list = np.array(features_list)
    print(f"\nâœ“ ç‰¹å¾æå–å®Œæˆ")
    print(f"  è¢«è¯•æ•°: {len(features_list)}")
    print(f"  ç‰¹å¾å½¢çŠ¶: {features_list[0].shape}")  # åº”è¯¥æ˜¯ (116, 308) æˆ– (116, 116)
    print(f"  ç‰¹å¾ç±»å‹: {'Hybrid (Deep+Stat)' if has_encoder else 'Statistical Only'}")

    return features_list


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    from abide_data_baseline import ABIDEBaselineProcessor

    processor = ABIDEBaselineProcessor()
    timeseries_list, labels, _, _ = processor.download_and_extract(n_subjects=10)

    features = extract_node_features_pretrained(
        timeseries_list,
        encoder_path='./pretrained_models/node_encoder_best.pth',
        embedding_dim=64,
        device='cuda'
    )

    print(f"\næå–çš„ç‰¹å¾å½¢çŠ¶: {features[0].shape}")